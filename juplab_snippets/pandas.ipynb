{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec48171-8734-4f10-9ec2-a178764d31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME WITH HEADERS\n",
    "df_conditions = pd.DataFrame(condition, columns=['status','attribute','database','api','identity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091c6f1-a8db-44e4-b9a9-17bb63e7b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE TO CSV\n",
    "df.to_csv(directory_path + '/review.csv', index=False, sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3596ce-ee6d-4829-94f7-65d27253ff90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# UPDATE DATAFRAME\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf2\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDJs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdj\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# UPDATE DATAFRAME (loc)\n",
    "df2.loc[df2['event_type'] == 'DJs', 'event_type'] = 'dj'\n",
    "\n",
    "# UPDATE DATAFRAME (lambda)\n",
    "df['width'] = df.apply(lambda x: len(str(x['extra'])) if str(x['extra']) != '' else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e09f14-e82d-4864-a152-5e6a9f76673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV\n",
    "import pandas as pd\n",
    "directory_path = os.getcwd()\n",
    "df_detail_all = pd.read_csv(directory_path + '/detail.csv')\n",
    "df_best = df_detail_all.loc[(df_detail_all['rank'] > 4) & (df_detail_all['rank'] < 5)]\n",
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a50be21-bcf6-464a-a2de-9d437c28b306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_identity</th>\n",
       "      <th>station_identity</th>\n",
       "      <th>detail_name</th>\n",
       "      <th>address</th>\n",
       "      <th>category</th>\n",
       "      <th>colour</th>\n",
       "      <th>detail_deletion</th>\n",
       "      <th>detail_latitude</th>\n",
       "      <th>detail_longitude</th>\n",
       "      <th>extra</th>\n",
       "      <th>place</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d9c8d4e-fa1d-433d-aea4-ff3f5c36cb64</td>\n",
       "      <td>f5b94c64-beb5-4295-95a1-34fc1f5b5a8d</td>\n",
       "      <td>Shard Quarter</td>\n",
       "      <td>297 Hoxton St, London N1 5JX, UK</td>\n",
       "      <td>Bar</td>\n",
       "      <td>#000000</td>\n",
       "      <td>True</td>\n",
       "      <td>51.5043</td>\n",
       "      <td>-0.086371</td>\n",
       "      <td>Women made wine shop</td>\n",
       "      <td>ChIJta8CEZoddkgRzUPFFO6tYHc</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pub_identity                      station_identity  \\\n",
       "0  6d9c8d4e-fa1d-433d-aea4-ff3f5c36cb64  f5b94c64-beb5-4295-95a1-34fc1f5b5a8d   \n",
       "\n",
       "     detail_name                           address category   colour  \\\n",
       "0  Shard Quarter  297 Hoxton St, London N1 5JX, UK      Bar  #000000   \n",
       "\n",
       "  detail_deletion  detail_latitude  detail_longitude                 extra  \\\n",
       "0            True          51.5043         -0.086371  Women made wine shop   \n",
       "\n",
       "                         place  rank  \n",
       "0  ChIJta8CEZoddkgRzUPFFO6tYHc   4.6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECTIVE COLUMNS\n",
    "df_new = df_details[['pub_identity','station_identity','name','address','category','latitude','longitude','place','rank']]\n",
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901f025-e46c-4ae8-9de7-97081e177fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN TABLES (add rows)\n",
    "df_appended = pd.concat([df_details, df_new], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2c225-6205-4a29-a4ae-69c06adf59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN TABLES (add columns)\n",
    "df_full = pd.merge(df_details, df_new, on='pub_identity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c050c-250f-402d-b160-3c790e9a2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER DATAFRAME (equal)\n",
    "filtered_values_id = filtered_values[(df_conditions['identity'] == '20ed1e3d-fe9d-41dd-af2b-136e49ed881b')]\n",
    "\n",
    "# FILTER DATAFRAME (or)\n",
    "df_join = df_join.loc[(df_join['music'] == '1')|(df_join['music'] == 1)]\n",
    "\n",
    "# FILTER DATAFRAME (and)\n",
    "df_evnt2 = df_evnt.loc[(df_evnt['event_type'] == 'comedy')&(df_evnt['event_type'] == 'sport')]\n",
    "df_filtered = df_eve[(df_eve['event_type'] != 'Quiz') & (df_eve['event_type'] != 'Live music' ) & (df_eve['event_type'] != 'Closed' )]\n",
    "\n",
    "# FILTER DATAFRAME (is na)\n",
    "filtered_df = df_join[df_join['event_identity'].isna()]\n",
    "\n",
    "# FILTER DATAFRAME (NumPy where clause)\n",
    "df_rev['review_identity']=np.where(df_rev['review_identity'].isna(),str(uuid.uuid4()),df_rev['review_identity'])\n",
    "\n",
    "# FILTER DATAFRAME (is null)\n",
    "filtered_values = df_conditions[(df_conditions['database'].isnull()) & (df_conditions['status'] != 'NO ATTRIBUTE')]\n",
    "\n",
    "# FILTER DATAFRAME (not null)\n",
    "df[['detail_name','extra','width']].loc[(df['extra'] != 'No details on this pub') & (df['width'] >1) & (df['width'] <50) & (df['extra'].notnull())]\n",
    "\n",
    "# FILTER DATAFRAME (column length)\n",
    "small = df.loc[len(df['extra']) < 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4022aba-3e82-4ba5-9031-8582ad1a0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLICE DATAFRAME\n",
    "df.loc[3276:3297]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84735c21-7a59-4c1d-b215-251564d8664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME LENGTH (no of rows)\n",
    "df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac4b5f-fe73-47d6-8771-4fa39d0ac206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT DATAFRAME\n",
    "filtered_df[['pub_identity','detail_name','address', 'station_name','event_type']].sort_values('station_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d542a-387c-4f8b-b696-641c6b82dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE VALUES\n",
    "df_station['direction_identity'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b148f4-b92a-436e-9e7a-8cf07de07fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TWO DATAFRAMES (isin)\n",
    "df_missing = df_det[~df_det['pub_identity'].isin(df['pub_identity'])]\n",
    "\n",
    "# COMPARE TWO DATAFRAMES (merge indicator)\n",
    "df_all = df1.merge(df2, on=['pub_identity'], how='right', indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4d59c-b585-436f-9c41-dadf33868fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT DATAFRAME COLUMN TO LIST\n",
    "df_missing['pub_identity'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e634f2d-31a8-4f3d-94b6-61564632e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE / DROP A COLUMN\n",
    "df_evnt3 = df_evnt.drop(df_evnt[df_evnt['event_type'] == 'TBC'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46802019-5c04-44db-8bb8-898f6556a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP DUPLICATES\n",
    "dfItem_all = dfItem_all.drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1699aa3-ce3a-492a-958f-dc12a71d8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATE DATAFRAME\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "directory_path = os.getcwd()\n",
    "\n",
    "# df[['extra','place','url','website']]\n",
    "\n",
    "base_url = 'https://maps.googleapis.com/maps/api/place/details/json?'\n",
    "key = 'xxx'\n",
    "# fields = 'name,url,website,editorial_summary'\n",
    "fields = 'address_component'\n",
    "df_detail = pd.read_csv(directory_path + '/detail.csv')\n",
    "\n",
    "for index, row in df_detail.iterrows():\n",
    "\n",
    "    name = row['detail_name']\n",
    "    pub_id = row['pub_identity']\n",
    "    website = row['website']\n",
    "    url = row['url']\n",
    "    extra = row['extra']\n",
    "    place_id = row['place']\n",
    "    # place_id = 'ChIJta8CEZoddkgRzUPFFO6tYHc'\n",
    "    full_url = base_url + \"place_id=\" + place_id + \"&key=\" + key + \"&fields=\" + fields\n",
    "\n",
    "    try:\n",
    "        response = requests.get(full_url)\n",
    "\n",
    "        components_by_type = {};\n",
    "        for x in response.json()['result']['address_components']:\n",
    "            components_by_type[x['types'][0]] = x['short_name']\n",
    "        \n",
    "#         for y in components_by_type:\n",
    "#             print(components_by_type[y])\n",
    "        if components_by_type['route'] != 'Greater':\n",
    "            try:\n",
    "                new_address = \"{} {}, {}\".format(components_by_type['street_number'],components_by_type['route'],components_by_type['postal_code'])\n",
    "            except:\n",
    "                new_address = \"{}, {}, {}\".format(components_by_type['premise'],components_by_type['route'],components_by_type['postal_code'])\n",
    "\n",
    "            # print(str(index) + ' : ' + new_address)\n",
    "            df_detail.loc[df_detail['pub_identity'] == pub_id, 'address'] = new_address\n",
    "        else:\n",
    "            print(response.json())\n",
    "    except:\n",
    "        print(response.json())\n",
    "\n",
    "df_detail.to_csv(directory_path + '/detail.csv', index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "\"\"\"\n",
    "    print(response.json())\n",
    "    print('**********')\n",
    "    print(response.json()['result']['address_components'].length)\n",
    "    break;\n",
    "    \n",
    "    try:\n",
    "        new_name = response.json()['result']['name']\n",
    "        if (name != new_name):\n",
    "            print('name :-')\n",
    "            print(name + ' | ' + new_name + ' : MISMATCHES')\n",
    "            df_detail.loc[df_detail['pub_identity'] == pub_id, 'detail_name'] = new_name\n",
    "            \n",
    "        try:\n",
    "            new_website = response.json()['result']['website']\n",
    "            if (website != new_website):\n",
    "                print('website :-')\n",
    "                print(website + ' | ' + new_website + ' : MISMATCHES')\n",
    "                df_detail.loc[df_detail['pub_identity'] == pub_id, 'website'] = new_website\n",
    "        except Exception:\n",
    "            pass\n",
    "            # print('no website for: ' + new_name)\n",
    "            # print('current website saved: ' + website)\n",
    "\n",
    "        try:\n",
    "            new_url = response.json()['result']['url']\n",
    "            if (url != new_url):\n",
    "                print('url :-')\n",
    "                print(url + ' | ' + new_url + ' : MISMATCHES')\n",
    "                df_detail.loc[df_detail['pub_identity'] == pub_id, 'url'] = new_url\n",
    "        except Exception:\n",
    "            pass\n",
    "            # print('no url for: ' + new_name)\n",
    "            # print('current url saved: ' + url)\n",
    "\n",
    "        try:    \n",
    "            new_extra = response.json()['result']['editorial_summary']['overview']\n",
    "            if (extra != new_extra):\n",
    "                print('extra :-')\n",
    "                print(extra + ' | ' + new_extra + ' : MISMATCHES')\n",
    "                df_detail.loc[df_detail['pub_identity'] == pub_id, 'extra'] = new_extra\n",
    "        except Exception:\n",
    "            pass\n",
    "            # print('no summary for: ' + new_name)\n",
    "            # print('current summary saved: ' + extra)\n",
    "\n",
    "    except:\n",
    "        print('Error')\n",
    "        print('csv name: ' + name)\n",
    "        print('csv pub id: ' + pub_id)\n",
    "        print('csv place id: ' + place_id)\n",
    "        print('response: ')\n",
    "        print(response.json())\n",
    "df_detail.to_csv(directory_path + '/detail.csv', index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "    # break\n",
    "    \n",
    "# place_id = 'ChIJy2QpfVUDdkgR_ZjHMTwf28A'\n",
    "# key = 'xx'\n",
    "# fields = 'name,url,website,photos,editorial_summary'\n",
    "# full_url = base_url + \"place_id=\" + place_id + \"&key=\" + key + \"&fields=\" + fields\n",
    "# response = requests.get(full_url)\n",
    "# # print(response.json())\n",
    "# response.json()['result']['name']\n",
    "# response.json()['result']['url']\n",
    "# response.json()['result']['website']\n",
    "# response.json()['result']['editorial_summary']['overview']\n",
    "# # print(len(response.json()['result']['photos']))\n",
    "\n",
    "# fruits = response.json()['result']['photos']\n",
    "# for x in fruits:\n",
    "#   print(x['photo_reference'])\n",
    "     \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e683de9-e8cd-4270-af86-ec3360005246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{pathway}/files/df_combined.csv')\n",
    "df['station_name'] = ''\n",
    "df_station = pd.read_csv(f'{pathway}/files/station.csv')\n",
    "df_station\n",
    "data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    records = []\n",
    "    ids = row['pub_identity']\n",
    "    name = row['detail_name']\n",
    "    st_id = row['station_identity'] if len(str(row['station_identity'])) > 0 else '' \n",
    "    lat = row['detail_latitude']\n",
    "    lng = row['detail_longitude']\n",
    "\n",
    "    for index, row in df_station.iterrows():\n",
    "        lat_diff = abs(row['station_latitude'] - lat)\n",
    "        lng_diff = abs(row['station_longitude'] - lng)\n",
    "        tot_diff = lat_diff + lng_diff\n",
    "        record = {'name': row['station_name'], 'id': row['station_identity'], 'distance': tot_diff}\n",
    "        records.append(record);\n",
    "  \n",
    "    sorted_stations = sorted(records, key=lambda x: x['distance'])\n",
    "    \n",
    "    df.loc[df['pub_identity'] == ids, 'station_name'] = sorted_stations[0]['name']\n",
    "    \n",
    "#     df['station_name'] = sorted_stations[0]['name']\n",
    "    data.append([name, \n",
    "                 st_id, \n",
    "                 sorted_stations[0]['name'],\n",
    "                 sorted_stations[0]['id'],\n",
    "                 'match' if st_id == sorted_stations[0]['id'] or st_id == '' else 'no match'])\n",
    "#     print(name, st_id, sorted_stations[0]['name'],sorted_stations[0]['id'],'match' if st_id == sorted_stations[0]['id'] or st_id == '' else 'no match')\n",
    "df_station_picks = pd.DataFrame(data, columns=['name','db_st','station_name','near_st','status'])\n",
    "# df_station_picks\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
